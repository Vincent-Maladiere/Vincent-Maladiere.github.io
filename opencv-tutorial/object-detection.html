<!DOCTYPE html><html><head><meta charSet="utf-8"/><title>Object Detection – Nextra</title><meta name="robots" content="index,follow"/><meta property="og:title" content="Object Detection – Nextra"/><meta name="theme-color" content="#111" media="(prefers-color-scheme: dark)"/><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover"/><style>
        :root {
          --nextra-primary-hue: 212deg;
          --nextra-primary-saturation: 100%;
          --nextra-navbar-height: 4rem;
          --nextra-menu-height: 3.75rem;
          --nextra-banner-height: 2.5rem;
        }
        
        .dark {
          --nextra-primary-hue: 204deg;
          --nextra-primary-saturation: 100%;
        }
      </style><meta name="msapplication-TileColor" content="#fff"/><meta http-equiv="Content-Language" content="en"/><meta name="description" content="Nextra: the next docs builder"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@shuding_"/><meta property="og:title" content="Nextra: the next docs builder"/><meta property="og:description" content="Nextra: the next docs builder"/><meta name="apple-mobile-web-app-title" content="Nextra"/><meta name="next-head-count" content="15"/><link rel="preload" href="/_next/static/media/2b753e56cc9cd730-s.p.ttf" as="font" type="font/ttf" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/6a8ba8707d180031-s.p.ttf" as="font" type="font/ttf" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/35d328148735ad9b-s.p.ttf" as="font" type="font/ttf" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/e687665822bfc06c.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e687665822bfc06c.css" data-n-g=""/><link rel="preload" href="/_next/static/css/7acdf249f868d277.css" as="style"/><link rel="stylesheet" href="/_next/static/css/7acdf249f868d277.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-e81585bb9a6b8f4d.js" defer=""></script><script src="/_next/static/chunks/framework-0995a3e8436ddc4f.js" defer=""></script><script src="/_next/static/chunks/main-063a3325800c4ac4.js" defer=""></script><script src="/_next/static/chunks/pages/_app-fd0e6a9249fe2bdb.js" defer=""></script><script src="/_next/static/chunks/8247-006705128f44e93a.js" defer=""></script><script src="/_next/static/chunks/4537-8b7c0592cdb72347.js" defer=""></script><script src="/_next/static/chunks/pages/opencv-tutorial/object-detection-a8455c90e38395d8.js" defer=""></script><script src="/_next/static/_hxuzv8OXSuUBok_Sbmau/_buildManifest.js" defer=""></script><script src="/_next/static/_hxuzv8OXSuUBok_Sbmau/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_de6e4f"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div dir="ltr"><script>document.documentElement.setAttribute('dir','ltr')</script><div class="nextra-nav-container nx-sticky nx-top-0 nx-z-20 nx-w-full nx-bg-transparent print:nx-hidden"><div class="nextra-nav-container-blur nx-pointer-events-none nx-absolute nx-z-[-1] nx-h-full nx-w-full nx-bg-white dark:nx-bg-dark nx-shadow-[0_2px_4px_rgba(0,0,0,.02),0_1px_0_rgba(0,0,0,.06)] dark:nx-shadow-[0_-1px_0_rgba(255,255,255,.1)_inset] contrast-more:nx-shadow-[0_0_0_1px_#000] contrast-more:dark:nx-shadow-[0_0_0_1px_#fff]"></div><nav class="nx-mx-auto nx-flex nx-h-[var(--nextra-navbar-height)] nx-max-w-[90rem] nx-items-center nx-justify-end nx-gap-2 nx-pl-[max(env(safe-area-inset-left),1.5rem)] nx-pr-[max(env(safe-area-inset-right),1.5rem)]"><a class="nx-flex nx-items-center hover:nx-opacity-75 ltr:nx-mr-auto rtl:nx-ml-auto" href="/"><span>Vincent Maladiere</span></a><a class="nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-text-gray-600 hover:nx-text-gray-800 dark:nx-text-gray-400 dark:hover:nx-text-gray-200" aria-current="false" href="/proba-ml/home"><span class="nx-absolute nx-inset-x-0 nx-text-center">Proba ML</span><span class="nx-invisible nx-font-medium">Proba ML</span></a><a class="nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-text-gray-600 hover:nx-text-gray-800 dark:nx-text-gray-400 dark:hover:nx-text-gray-200" aria-current="false" href="/apply-2022/home"><span class="nx-absolute nx-inset-x-0 nx-text-center">Apply Conf 2022</span><span class="nx-invisible nx-font-medium">Apply Conf 2022</span></a><a class="nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-text-gray-600 hover:nx-text-gray-800 dark:nx-text-gray-400 dark:hover:nx-text-gray-200" aria-current="false" href="/contributing-scikit-learn/home"><span class="nx-absolute nx-inset-x-0 nx-text-center">Contributing to scikit-learn</span><span class="nx-invisible nx-font-medium">Contributing to scikit-learn</span></a><a class="nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-font-medium nx-subpixel-antialiased" aria-current="true" href="/opencv-tutorial/home"><span class="nx-absolute nx-inset-x-0 nx-text-center">OpenCV Tutorial</span><span class="nx-invisible nx-font-medium">OpenCV Tutorial</span></a><a class="nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-text-gray-600 hover:nx-text-gray-800 dark:nx-text-gray-400 dark:hover:nx-text-gray-200" aria-current="false" href="/about"><span class="nx-absolute nx-inset-x-0 nx-text-center">About</span><span class="nx-invisible nx-font-medium">About</span></a><a class="nx-text-sm contrast-more:nx-text-gray-700 contrast-more:dark:nx-text-gray-100 nx-relative -nx-ml-2 nx-hidden nx-whitespace-nowrap nx-p-2 md:nx-inline-block nx-font-medium nx-subpixel-antialiased" aria-current="true" href="mailto:maladiere.vincent@gmail.com"><span class="nx-absolute nx-inset-x-0 nx-text-center">Contact</span><span class="nx-invisible nx-font-medium">Contact</span></a><div class="nextra-search nx-relative md:nx-w-64 nx-hidden md:nx-inline-block mx-min-w-[200px]"><div class="nx-relative nx-flex nx-items-center nx-text-gray-900 contrast-more:nx-text-gray-800 dark:nx-text-gray-300 contrast-more:dark:nx-text-gray-300"><input spellcheck="false" class="nx-block nx-w-full nx-appearance-none nx-rounded-lg nx-px-3 nx-py-2 nx-transition-colors nx-text-base nx-leading-tight md:nx-text-sm nx-bg-black/[.05] dark:nx-bg-gray-50/10 focus:nx-bg-white dark:focus:nx-bg-dark placeholder:nx-text-gray-500 dark:placeholder:nx-text-gray-400 contrast-more:nx-border contrast-more:nx-border-current" type="search" placeholder="Search documentation…" value=""/></div></div><button type="button" aria-label="Menu" class="nextra-hamburger -nx-mr-2 nx-rounded nx-p-2 active:nx-bg-gray-400/20 md:nx-hidden"><svg fill="none" width="24" height="24" viewBox="0 0 24 24" stroke="currentColor" class=""><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16"></path></g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 12h16"></path><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 18h16"></path></g></svg></button></nav></div><div class="nx-mx-auto nx-flex nx-max-w-[90rem]"><div class="motion-reduce:nx-transition-none [transition:background-color_1.5s_ease] nx-bg-transparent"></div><aside class="nextra-sidebar-container nx-flex nx-flex-col md:nx-top-16 md:nx-shrink-0 motion-reduce:nx-transform-none nx-transform-gpu nx-transition-all nx-ease-in-out print:nx-hidden md:nx-w-64 md:nx-sticky md:nx-self-start max-md:[transform:translate3d(0,-100%,0)]"><div class="nx-px-4 nx-pt-4 md:nx-hidden"><div class="nextra-search nx-relative md:nx-w-64"><div class="nx-relative nx-flex nx-items-center nx-text-gray-900 contrast-more:nx-text-gray-800 dark:nx-text-gray-300 contrast-more:dark:nx-text-gray-300"><input spellcheck="false" class="nx-block nx-w-full nx-appearance-none nx-rounded-lg nx-px-3 nx-py-2 nx-transition-colors nx-text-base nx-leading-tight md:nx-text-sm nx-bg-black/[.05] dark:nx-bg-gray-50/10 focus:nx-bg-white dark:focus:nx-bg-dark placeholder:nx-text-gray-500 dark:placeholder:nx-text-gray-400 contrast-more:nx-border contrast-more:nx-border-current" type="search" placeholder="Search documentation…" value=""/></div></div></div><div class="nx-overflow-y-auto nx-overflow-x-hidden nx-p-4 nx-grow md:nx-h-[calc(100vh-var(--nextra-navbar-height)-var(--nextra-menu-height))] nextra-scrollbar"><div class="nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none"><div class="nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100"><ul class="nx-flex nx-flex-col nx-gap-1 nextra-menu-desktop max-md:nx-hidden"><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/opencv-tutorial/home">Home</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/opencv-tutorial/image-processing">1. Image Processing</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/opencv-tutorial/video-io">2. Video I/O</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/opencv-tutorial/2D-features-framework">3. 2d features framework</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/opencv-tutorial/camera-calibration-and-3D-reconstruction">4. Camera Calibration and 3D reconstruction</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/opencv-tutorial/video-analysis">5. Video Analysis</a></li><li class="nx-flex nx-flex-col nx-gap-1 active"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-bg-primary-100 nx-font-semibold nx-text-primary-800 dark:nx-bg-primary-400/10 dark:nx-text-primary-600 contrast-more:nx-border-primary-500 contrast-more:dark:nx-border-primary-500" href="/opencv-tutorial/object-detection">6. Object Detection</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/opencv-tutorial/machine-learning">7. Machine Learning</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/opencv-tutorial/core-module">8. Core Module</a></li></ul></div></div></div><div class="nx-sticky nx-bottom-0 nx-bg-white dark:nx-bg-dark nx-mx-4 nx-py-4 nx-shadow-[0_-12px_16px_#fff] nx-flex nx-items-center nx-gap-2 dark:nx-border-neutral-800 dark:nx-shadow-[0_-12px_16px_#111] contrast-more:nx-border-neutral-400 contrast-more:nx-shadow-none contrast-more:dark:nx-shadow-none nx-border-t" data-toggle-animation="off"><div class="nx-grow nx-flex nx-flex-col"><button title="Change theme" class="nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50" id="headlessui-listbox-button-:R2njcm:" type="button" aria-haspopup="listbox" aria-expanded="false" data-headlessui-state=""><div class="nx-flex nx-items-center nx-gap-2 nx-capitalize"><svg fill="none" viewBox="3 3 18 18" width="12" height="12" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" fill="currentColor" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"></path></svg><span class="">Light</span></div></button></div></div></aside><nav class="nextra-toc nx-order-last nx-hidden nx-w-64 nx-shrink-0 xl:nx-block print:nx-hidden nx-px-4" aria-label="table of contents"><div class="nextra-scrollbar nx-sticky nx-top-16 nx-overflow-y-auto nx-pr-4 nx-pt-6 nx-text-sm [hyphens:auto] nx-max-h-[calc(100vh-var(--nextra-navbar-height)-env(safe-area-inset-bottom))] ltr:-nx-mr-4 rtl:-nx-ml-4"><p class="nx-mb-4 nx-font-semibold nx-tracking-tight">On This Page</p><ul><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#haar-cascade-inference" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">Haar Cascade Inference</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#haar-cascade-training" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">Haar Cascade Training</a></li></ul><div class="nx-mt-8 nx-border-t nx-bg-white nx-pt-8 nx-shadow-[0_-12px_16px_white] dark:nx-bg-dark dark:nx-shadow-[0_-12px_16px_#111] nx-sticky nx-bottom-0 nx-flex nx-flex-col nx-items-start nx-gap-2 nx-pb-8 dark:nx-border-neutral-800 contrast-more:nx-border-t contrast-more:nx-border-neutral-400 contrast-more:nx-shadow-none contrast-more:dark:nx-border-neutral-400"><a href="https://github.com/Vincent-Maladiere/vincent-maladiere.github.io/issues/new?title=Feedback%20for%20%E2%80%9CObject%20Detection%E2%80%9D&amp;labels=feedback" target="_blank" rel="noreferrer" class="nx-text-xs nx-font-medium nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-100 contrast-more:nx-text-gray-800 contrast-more:dark:nx-text-gray-50">Question? Give us feedback →<span class="nx-sr-only nx-select-none"> (opens in a new tab)</span></a><a class="nx-text-xs nx-font-medium nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-100 contrast-more:nx-text-gray-800 contrast-more:dark:nx-text-gray-50" href="https://github.com/Vincent-Maladiere/vincent-maladiere.github.io/blob/master/pages/opencv-tutorial/object-detection.md">Edit this page</a></div></div></nav><div id="reach-skip-nav"></div><article class="nx-w-full nx-break-words nextra-content nx-flex nx-min-h-[calc(100vh-var(--nextra-navbar-height))] nx-min-w-0 nx-justify-center nx-pb-8 nx-pr-[calc(env(safe-area-inset-right)-1.5rem)]"><main class="nx-w-full nx-min-w-0 nx-max-w-6xl nx-px-6 nx-pt-4 md:nx-px-12"><div class="nextra-breadcrumb nx-mt-1.5 nx-flex nx-items-center nx-gap-1 nx-overflow-hidden nx-text-sm nx-text-gray-500 dark:nx-text-gray-400 contrast-more:nx-text-current"><div class="nx-whitespace-nowrap nx-transition-colors nx-min-w-[24px] nx-overflow-hidden nx-text-ellipsis" title="OpenCV Tutorial">OpenCV Tutorial</div><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-w-3.5 nx-shrink-0"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg><div class="nx-whitespace-nowrap nx-transition-colors nx-font-medium nx-text-gray-700 contrast-more:nx-font-bold contrast-more:nx-text-current dark:nx-text-gray-100 contrast-more:dark:nx-text-current" title="6. Object Detection">6. Object Detection</div></div><h1 class="nx-mt-2 nx-text-4xl nx-font-bold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100">Object Detection</h1>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">Haar Cascade Inference<a href="#haar-cascade-inference" id="haar-cascade-inference" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0"><a href="https://docs.opencv.org/4.5.0/db/d28/tutorial_cascade_classifier.html" target="_blank" rel="noreferrer" class="nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]">https://docs.opencv.org/4.5.0/db/d28/tutorial_cascade_classifier.html<span class="nx-sr-only nx-select-none"> (opens in a new tab)</span></a></p>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images.</p>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">Features extraction using Haar features.</p>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">They are just like our convolutional kernel.</li>
<li class="nx-my-2">Each feature is a single value obtained by subtracting sum of pixels under the white rectangle from sum of pixels under the black rectangle.</li>
</ul>
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0"><img alt="Screen Shot 2021-12-09 at 08.38.58.png" loading="lazy" width="648" height="554" decoding="async" data-nimg="1" style="color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 320 280&#x27;%3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAMAAAACh/xsAAAAJFBMVEX////z8/Pu7u739/fo6OiXl5e2trZjY2PBwcGlpaXHx8d7e3seuPCZAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAMklEQVR4nBXHxxHAQAwDsSUp6VL//XqMH1AxG4v70o2CxlYS3HsNErhKALUOLovpv/ABFvIAoy7Vs0MAAAAASUVORK5CYII=&#x27;/%3E%3C/svg%3E&quot;)" src="/_next/static/media/Screen_Shot_2021-12-09_at_08.38.58.1142c254.png"/></p>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">However large your image, it reduces the calculations for a given pixel to an operation involving just four pixels. Nice, isn&#x27;t it? It makes things super-fast.</p>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">But among all these features we calculated, most of them are irrelevant</li>
<li class="nx-my-2">The same windows applied to cheeks or any other place is irrelevant</li>
<li class="nx-my-2">So how do we select the best features out of 160000+ features? It is achieved by <strong>Adaboost</strong></li>
</ul>
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0"><img alt="Screen Shot 2021-12-09 at 08.44.51.png" loading="lazy" width="662" height="416" decoding="async" data-nimg="1" style="color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 320 200&#x27;%3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAMAAABPT11nAAAALVBMVEWjo6Pm5ub+/v7Dw8PZ2dlkZGSDg4Orq6uampq2traTk5OWlpbPz8/Q0NB1dXVLPACKAAAACXBIWXMAABYlAAAWJQFJUiTwAAAALElEQVR4nAXBhwEAIAgEsXuKCpb9xzXBTNQdhZlOhETImfRijn65M/Hl4JsPEJQAwjEzPosAAAAASUVORK5CYII=&#x27;/%3E%3C/svg%3E&quot;)" src="/_next/static/media/Screen_Shot_2021-12-09_at_08.44.51.7b9a6061.png"/></p>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">For this, we apply each and every feature on all the training images. For each feature, it finds the best threshold which will classify the faces to positive and negative.</p>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Obviously, there will be errors or misclassifications. We select the features with minimum error rate, which means they are the features that most accurately classify the face and non-face images</li>
<li class="nx-my-2">The final classifier is a weighted sum of these weak classifiers.</li>
</ul>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">In an image, most of the image is non-face region.</p>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">So it is a better idea to have a simple method to check if a window is not a face region.</li>
<li class="nx-my-2">For this they introduced the concept of <strong>Cascade of Classifiers</strong>. Instead of applying all 6000 features on a window, the features are grouped into different stages of classifiers and applied one-by-one.</li>
<li class="nx-my-2">If a window fails the first stage, discard it.</li>
<li class="nx-my-2">The authors&#x27; detector had 6000+ features with 38 stages with 1, 10, 25, 25 and 50 features in the first five stages</li>
</ul>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">full script</p>
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="python" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="python" data-theme="default"><span class="line"><span style="color:var(--shiki-token-keyword)">from</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-constant)">__future__</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">import</span><span style="color:var(--shiki-color-text)"> print_function</span></span>
<span class="line"><span style="color:var(--shiki-token-keyword)">import</span><span style="color:var(--shiki-color-text)"> cv2 </span><span style="color:var(--shiki-token-keyword)">as</span><span style="color:var(--shiki-color-text)"> cv</span></span>
<span class="line"><span style="color:var(--shiki-token-keyword)">import</span><span style="color:var(--shiki-color-text)"> argparse</span></span>
<span class="line"> </span>
<span class="line"><span style="color:var(--shiki-token-keyword)">def</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-function)">detectAndDisplay</span><span style="color:var(--shiki-color-text)">(</span><span style="color:var(--shiki-token-parameter)">frame</span><span style="color:var(--shiki-color-text)">):</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    frame_gray </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> cv</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">cvtColor</span><span style="color:var(--shiki-token-punctuation)">(frame, cv.COLOR_BGR2GRAY)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    frame_gray </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> cv</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">equalizeHist</span><span style="color:var(--shiki-token-punctuation)">(frame_gray)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-comment)">#-- Detect faces</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    faces </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> face_cascade</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">detectMultiScale</span><span style="color:var(--shiki-token-punctuation)">(frame_gray)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-keyword)">for</span><span style="color:var(--shiki-color-text)"> (x</span><span style="color:var(--shiki-token-punctuation)">,</span><span style="color:var(--shiki-color-text)">y</span><span style="color:var(--shiki-token-punctuation)">,</span><span style="color:var(--shiki-color-text)">w</span><span style="color:var(--shiki-token-punctuation)">,</span><span style="color:var(--shiki-color-text)">h) </span><span style="color:var(--shiki-token-keyword)">in</span><span style="color:var(--shiki-color-text)"> faces</span><span style="color:var(--shiki-token-punctuation)">:</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">        center </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> (x </span><span style="color:var(--shiki-token-keyword)">+</span><span style="color:var(--shiki-color-text)"> w</span><span style="color:var(--shiki-token-keyword)">//</span><span style="color:var(--shiki-token-constant)">2</span><span style="color:var(--shiki-token-punctuation)">,</span><span style="color:var(--shiki-color-text)"> y </span><span style="color:var(--shiki-token-keyword)">+</span><span style="color:var(--shiki-color-text)"> h</span><span style="color:var(--shiki-token-keyword)">//</span><span style="color:var(--shiki-token-constant)">2</span><span style="color:var(--shiki-color-text)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">        frame </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> cv</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">ellipse</span><span style="color:var(--shiki-token-punctuation)">(frame, center, (w</span><span style="color:var(--shiki-token-keyword)">//</span><span style="color:var(--shiki-token-constant)">2</span><span style="color:var(--shiki-token-punctuation)">, h</span><span style="color:var(--shiki-token-keyword)">//</span><span style="color:var(--shiki-token-constant)">2</span><span style="color:var(--shiki-token-punctuation)">), </span><span style="color:var(--shiki-token-constant)">0</span><span style="color:var(--shiki-token-punctuation)">, </span><span style="color:var(--shiki-token-constant)">0</span><span style="color:var(--shiki-token-punctuation)">, </span><span style="color:var(--shiki-token-constant)">360</span><span style="color:var(--shiki-token-punctuation)">, (</span><span style="color:var(--shiki-token-constant)">255</span><span style="color:var(--shiki-token-punctuation)">, </span><span style="color:var(--shiki-token-constant)">0</span><span style="color:var(--shiki-token-punctuation)">, </span><span style="color:var(--shiki-token-constant)">255</span><span style="color:var(--shiki-token-punctuation)">), </span><span style="color:var(--shiki-token-constant)">4</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">        faceROI </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> frame_gray</span><span style="color:var(--shiki-token-punctuation)">[</span><span style="color:var(--shiki-color-text)">y</span><span style="color:var(--shiki-token-punctuation)">:</span><span style="color:var(--shiki-color-text)">y</span><span style="color:var(--shiki-token-keyword)">+</span><span style="color:var(--shiki-color-text)">h</span><span style="color:var(--shiki-token-punctuation)">,</span><span style="color:var(--shiki-color-text)">x</span><span style="color:var(--shiki-token-punctuation)">:</span><span style="color:var(--shiki-color-text)">x</span><span style="color:var(--shiki-token-keyword)">+</span><span style="color:var(--shiki-color-text)">w</span><span style="color:var(--shiki-token-punctuation)">]</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">        </span><span style="color:var(--shiki-token-comment)">#-- In each face, detect eyes</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">        eyes </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> eyes_cascade</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">detectMultiScale</span><span style="color:var(--shiki-token-punctuation)">(faceROI)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">        </span><span style="color:var(--shiki-token-keyword)">for</span><span style="color:var(--shiki-color-text)"> (x2</span><span style="color:var(--shiki-token-punctuation)">,</span><span style="color:var(--shiki-color-text)">y2</span><span style="color:var(--shiki-token-punctuation)">,</span><span style="color:var(--shiki-color-text)">w2</span><span style="color:var(--shiki-token-punctuation)">,</span><span style="color:var(--shiki-color-text)">h2) </span><span style="color:var(--shiki-token-keyword)">in</span><span style="color:var(--shiki-color-text)"> eyes</span><span style="color:var(--shiki-token-punctuation)">:</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">            eye_center </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> (x </span><span style="color:var(--shiki-token-keyword)">+</span><span style="color:var(--shiki-color-text)"> x2 </span><span style="color:var(--shiki-token-keyword)">+</span><span style="color:var(--shiki-color-text)"> w2</span><span style="color:var(--shiki-token-keyword)">//</span><span style="color:var(--shiki-token-constant)">2</span><span style="color:var(--shiki-token-punctuation)">,</span><span style="color:var(--shiki-color-text)"> y </span><span style="color:var(--shiki-token-keyword)">+</span><span style="color:var(--shiki-color-text)"> y2 </span><span style="color:var(--shiki-token-keyword)">+</span><span style="color:var(--shiki-color-text)"> h2</span><span style="color:var(--shiki-token-keyword)">//</span><span style="color:var(--shiki-token-constant)">2</span><span style="color:var(--shiki-color-text)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">            radius </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-constant)">int</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-function)">round</span><span style="color:var(--shiki-token-punctuation)">((w2 </span><span style="color:var(--shiki-token-keyword)">+</span><span style="color:var(--shiki-token-punctuation)"> h2)</span><span style="color:var(--shiki-token-keyword)">*</span><span style="color:var(--shiki-token-constant)">0.25</span><span style="color:var(--shiki-token-punctuation)">))</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">            frame </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> cv</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">circle</span><span style="color:var(--shiki-token-punctuation)">(frame, eye_center, radius, (</span><span style="color:var(--shiki-token-constant)">255</span><span style="color:var(--shiki-token-punctuation)">, </span><span style="color:var(--shiki-token-constant)">0</span><span style="color:var(--shiki-token-punctuation)">, </span><span style="color:var(--shiki-token-constant)">0</span><span style="color:var(--shiki-token-punctuation)"> ), </span><span style="color:var(--shiki-token-constant)">4</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    cv</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">imshow</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&#x27;Capture - Face detection&#x27;</span><span style="color:var(--shiki-token-punctuation)">, frame)</span></span>
<span class="line"> </span>
<span class="line"><span style="color:var(--shiki-color-text)">parser </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> argparse</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">ArgumentParser</span><span style="color:var(--shiki-token-punctuation)">(description</span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-token-string-expression)">&#x27;Code for Cascade Classifier tutorial.&#x27;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">parser</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">add_argument</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&#x27;--face_cascade&#x27;</span><span style="color:var(--shiki-token-punctuation)">, help</span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-token-string-expression)">&#x27;Path to face cascade.&#x27;</span><span style="color:var(--shiki-token-punctuation)">, default</span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-token-string-expression)">&#x27;data/haarcascades/haarcascade_frontalface_alt.xml&#x27;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">parser</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">add_argument</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&#x27;--eyes_cascade&#x27;</span><span style="color:var(--shiki-token-punctuation)">, help</span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-token-string-expression)">&#x27;Path to eyes cascade.&#x27;</span><span style="color:var(--shiki-token-punctuation)">, default</span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-token-string-expression)">&#x27;data/haarcascades/haarcascade_eye_tree_eyeglasses.xml&#x27;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">parser</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">add_argument</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&#x27;--camera&#x27;</span><span style="color:var(--shiki-token-punctuation)">, help</span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-token-string-expression)">&#x27;Camera divide number.&#x27;</span><span style="color:var(--shiki-token-punctuation)">, type</span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-token-constant)">int</span><span style="color:var(--shiki-token-punctuation)">, default</span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-token-constant)">0</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">args </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> parser</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">parse_args</span><span style="color:var(--shiki-token-punctuation)">()</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">face_cascade_name </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> args</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">face_cascade</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">eyes_cascade_name </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> args</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">eyes_cascade</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">face_cascade </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> cv</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">CascadeClassifier</span><span style="color:var(--shiki-token-punctuation)">()</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">eyes_cascade </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> cv</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">CascadeClassifier</span><span style="color:var(--shiki-token-punctuation)">()</span></span>
<span class="line"> </span>
<span class="line"><span style="color:var(--shiki-token-comment)">#-- 1. Load the cascades</span></span>
<span class="line"><span style="color:var(--shiki-token-keyword)">if</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">not</span><span style="color:var(--shiki-color-text)"> face_cascade</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">load</span><span style="color:var(--shiki-token-punctuation)">(cv.samples.</span><span style="color:var(--shiki-token-function)">findFile</span><span style="color:var(--shiki-token-punctuation)">(face_cascade_name)):</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-function)">print</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&#x27;--(!)Error loading face cascade&#x27;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-function)">exit</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-constant)">0</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-token-keyword)">if</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">not</span><span style="color:var(--shiki-color-text)"> eyes_cascade</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">load</span><span style="color:var(--shiki-token-punctuation)">(cv.samples.</span><span style="color:var(--shiki-token-function)">findFile</span><span style="color:var(--shiki-token-punctuation)">(eyes_cascade_name)):</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-function)">print</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&#x27;--(!)Error loading eyes cascade&#x27;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-function)">exit</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-constant)">0</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">camera_device </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> args</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">camera</span></span>
<span class="line"> </span>
<span class="line"><span style="color:var(--shiki-token-comment)">#-- 2. Read the video stream</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">cap </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> cv</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">VideoCapture</span><span style="color:var(--shiki-token-punctuation)">(camera_device)</span></span>
<span class="line"><span style="color:var(--shiki-token-keyword)">if</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">not</span><span style="color:var(--shiki-color-text)"> cap</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">isOpened</span><span style="color:var(--shiki-token-punctuation)">:</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-function)">print</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&#x27;--(!)Error opening video capture&#x27;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-function)">exit</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-constant)">0</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-token-keyword)">while</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-constant)">True</span><span style="color:var(--shiki-token-punctuation)">:</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    ret</span><span style="color:var(--shiki-token-punctuation)">,</span><span style="color:var(--shiki-color-text)"> frame </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> cap</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">read</span><span style="color:var(--shiki-token-punctuation)">()</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-keyword)">if</span><span style="color:var(--shiki-color-text)"> frame </span><span style="color:var(--shiki-token-keyword)">is</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-constant)">None</span><span style="color:var(--shiki-token-punctuation)">:</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">        </span><span style="color:var(--shiki-token-function)">print</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&#x27;--(!) No captured frame -- Break!&#x27;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">        </span><span style="color:var(--shiki-token-keyword)">break</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-function)">detectAndDisplay</span><span style="color:var(--shiki-token-punctuation)">(frame)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">    </span><span style="color:var(--shiki-token-keyword)">if</span><span style="color:var(--shiki-color-text)"> cv</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">waitKey</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-constant)">10</span><span style="color:var(--shiki-token-punctuation)">)</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">==</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-constant)">27</span><span style="color:var(--shiki-token-punctuation)">:</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">        </span><span style="color:var(--shiki-token-keyword)">break</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">Haar Cascade Training<a href="#haar-cascade-training" id="haar-cascade-training" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0"><a href="https://docs.opencv.org/4.5.0/dc/d88/tutorial_traincascade.html" target="_blank" rel="noreferrer" class="nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]">https://docs.opencv.org/4.5.0/dc/d88/tutorial_traincascade.html<span class="nx-sr-only nx-select-none"> (opens in a new tab)</span></a></p>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">The <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">opencv_traincascade</code> supports both HAAR like wavelet features <a href="https://docs.opencv.org/4.5.0/d0/de3/citelist.html#CITEREF_Viola01" target="_blank" rel="noreferrer" class="nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]"><strong>[248]</strong><span class="nx-sr-only nx-select-none"> (opens in a new tab)</span></a> and LBP (Local Binary Patterns) <a href="https://docs.opencv.org/4.5.0/d0/de3/citelist.html#CITEREF_Liao2007" target="_blank" rel="noreferrer" class="nx-text-primary-600 nx-underline nx-decoration-from-font [text-underline-position:from-font]"><strong>[140]</strong><span class="nx-sr-only nx-select-none"> (opens in a new tab)</span></a> feature</p>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">LBP features yield integer precision in contrast to HAAR features, yielding floating point precision, so both training and detection with LBP are several times faster then with HAAR features.</li>
</ul>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">We need a set of positive samples (containing actual objects you want to detect) and a set of negative images (containing everything you do not want to detect).</p>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">The set of negative samples must be prepared manually, whereas set of positive samples is created using the <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">opencv_createsamples</code> application.</li>
</ul>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">Negative samples may be of different sizes.</p>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">However, each image should be equal or larger than the desired training window size <em>(which corresponds to the model dimensions, most of the times being the average size of your object)</em></li>
<li class="nx-my-2">These images are used to subsample one negative image into several image samples having this training window size.</li>
</ul>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">2 ways of generating positive samples</p>
<ol class="nx-mt-6 nx-list-decimal first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Generate a bunch of positives from a single positive object image.</li>
<li class="nx-my-2">Supply all the positives yourself and only use the tool to cut them out, resize them and put them in the opencv needed binary format (better)</li>
</ol>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">100 real object images, can lead to a better model than 1000 artificially generated positives, by using the <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">opencv_createsamples</code> application</p>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">Structure</p>
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="text" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="text" data-theme="default"><span class="line"><span style="color:var(--shiki-color-text)">/img</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">  img1.jpg</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">  img2.jpg</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">info.dat</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">info.dat</p>
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="text" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="text" data-theme="default"><span class="line"><span style="color:var(--shiki-color-text)">img/img1.jpg  1  140 100 45 45</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">img/img2.jpg  2  100 200 50 50   50 30 25 25</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">The manual process of creating the <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">info</code> file can also been done by using the opencv_annotation tool.</p>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">This is an open source tool for visually selecting the regions of interest of your object instances in any given images.</li>
<li class="nx-my-2">The project need to be build (git clone)</li>
<li class="nx-my-2"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">opencv_annotation --annotations=/path/to/annotations/file.txt --images=/path/to/image/folder/</code></li>
</ul>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">Next step is to train the model: <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">opencv_traincascade</code></p>
</li>
<li class="nx-my-2">
<p class="nx-mt-6 nx-leading-7 first:nx-mt-0">Visualize the classifier with <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">opencv_visualisation --image=/data/object.png --model=/data/model.xml --data=/data/result/</code></p>
</li>
</ul><div class="nx-mt-16"></div><div class="nx-mb-8 nx-flex nx-items-center nx-border-t nx-pt-8 dark:nx-border-neutral-800 contrast-more:nx-border-neutral-400 dark:contrast-more:nx-border-neutral-400 print:nx-hidden"><a title="5. Video Analysis" class="nx-flex nx-max-w-[50%] nx-items-center nx-gap-1 nx-py-4 nx-text-base nx-font-medium nx-text-gray-600 nx-transition-colors [word-break:break-word] hover:nx-text-primary-600 dark:nx-text-gray-300 md:nx-text-lg ltr:nx-pr-4 rtl:nx-pl-4" href="/opencv-tutorial/video-analysis"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-inline nx-h-5 nx-shrink-0 ltr:nx-rotate-180"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>5. Video Analysis</a><a title="7. Machine Learning" class="nx-flex nx-max-w-[50%] nx-items-center nx-gap-1 nx-py-4 nx-text-base nx-font-medium nx-text-gray-600 nx-transition-colors [word-break:break-word] hover:nx-text-primary-600 dark:nx-text-gray-300 md:nx-text-lg ltr:nx-ml-auto ltr:nx-pl-4 ltr:nx-text-right rtl:nx-mr-auto rtl:nx-pr-4 rtl:nx-text-left" href="/opencv-tutorial/machine-learning">7. Machine Learning<svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-inline nx-h-5 nx-shrink-0 rtl:nx-rotate-180"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg></a></div></main></article></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/opencv-tutorial/object-detection","query":{},"buildId":"_hxuzv8OXSuUBok_Sbmau","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>